{
 "cells": [
  {
   "attachments": {
    "15f80e87-d32d-4a93-8a98-5d8458eed246.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random Search Method\n",
    "\n",
    "What is the random search method?\n",
    "\r\n",
    "The random search method is a simple approach for hyperparameter optimization in ML. It is a popular technique widely used by practitioners because of its simplicity and ease of implementation. Weâ€™ll learn its theory and how to apply it in a simple ML project using the open-source Python library called scikit-learn.\r\n",
    "\r\n",
    "The random search method involves selecting random combinations of hyperparameter values of a particular ML algorithm, such as logistic regression. Then it evaluates the performances of the ML model using the selected combination of hyperparameter values.\r\n",
    "\r\n",
    "It repeats this process for a fixed number of iterations with different combinations of hyperparameter values that are randomly selected. This can be done by defining a range of values for each hyperparameter and then randomly sampling from these ranges for each itera\n",
    "\n",
    "![image.png](attachment:15f80e87-d32d-4a93-8a98-5d8458eed246.png)\n",
    "\n",
    "One of the key advantages of the random search method is that it is computationally efficient. It only evaluates a fixed number of random combinations, so it is not as computationally expensive as other methods, such as grid search or Bayesian optimization.\r\n",
    "\r\n",
    "Finally, the combination of hyperparameter values that produce the best performance is selected as a final set of hyperparameters for the ML models. The final set of hyperparameters can then train the final ML model on the entire dataset. This approach is simple yet effective, and it is a great starting point for any ML practitioners who are new to hyperparameter optimization.\r\n",
    "\r\n",
    "The random search method does not try to use all hyperparameter values we have specified; itâ€™ll only select a few of them based on the number of iterations. If we set the number of iterations to five, itâ€™ll randomly select five different combinations of hyperparameters to determine which one of them produces an ML model with the best performane.tion.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Important packages\n",
    "First, we import important Python packages that will do the following tasks:\n",
    "\n",
    "- Load the dataset.\n",
    "- Clean the dataset.\n",
    "- Process the dataset using feature engineering techniques.\n",
    "- Create and train machine learning model (logistic regression).\n",
    "- Check machine learning model performance.\n",
    "- Implement the random search method.\n",
    "- Identify combination of hyperparameters that provide the best results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.448217Z",
     "start_time": "2024-01-17T09:13:10.439342Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import important modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Seeding\n",
    "np.random.seed(123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Load the dataset\n",
    "We will use pandas to load the dataset from the data folder. The name of the dataset is\n",
    "loan_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.476945Z",
     "start_time": "2024-01-17T09:13:10.450242Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data_path = \"loan_data.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Letâ€™s see the first five rows of the dataset using the head() method from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.487466Z",
     "start_time": "2024-01-17T09:13:10.478021Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top five rows of data\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see, the dataset has 13 columns.\n",
    "\n",
    "- Loan_ID: Unique loan ID\n",
    "- Gender: Male/Female \n",
    "- Married: Applicant married (Y/N)\n",
    "- Dependents: Number of dependents\n",
    "- Education: Applicant education (Graduate/Undergraduate)\n",
    "- Self_Employed: Self-employed (Y/N)\n",
    "- ApplicantIncome: Applicant income\n",
    "- CoapplicantIncome: Co-applicant income\n",
    "- LoanAmount: Loan amount in thousands\n",
    "- Loan_Amount_Term: Term of the loan in months\n",
    "- Credit_History: Credit history meets guidelines\n",
    "- Property_Area: Urban/Semi-Urban/Rural\n",
    "- Loan_Status: Loan approved (Y/N)\n",
    "\n",
    "The shape method from pandas will let us know the total number of rows and columns available in\n",
    "the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.490126Z",
     "start_time": "2024-01-17T09:13:10.488289Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 614 loan data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas method called info() provides more details about each column presented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.502158Z",
     "start_time": "2024-01-17T09:13:10.491663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information above shows that the dataset has columns with different data types, such as object/string, integers, and float."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check missing values\n",
    "\n",
    "It is important to clean the dataset by checking if it has any missing values before starting to\n",
    "train the machine learning model.\n",
    "\n",
    "The following code will provide a total of missing values for each column presented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.506601Z",
     "start_time": "2024-01-17T09:13:10.502887Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The output shows that our dataset has some missing values in different columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's convert some values in the Loan_Status and Dependents columns into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     345\n",
       "1     102\n",
       "2     101\n",
       "3+     51\n",
       "Name: Dependents, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Dependents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    422\n",
       "N    192\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.511107Z",
     "start_time": "2024-01-17T09:13:10.507448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with numerical values\n",
    "data['Dependents'].replace('3+', 3,inplace=True)\n",
    "data['Loan_Status'].replace('N', 0,inplace=True)\n",
    "data['Loan_Status'].replace('Y', 1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with object data type, we use the mode() function from pandas to identify the most common value in that particular column and insert the identified value into all missing points in the column.\n",
    "\n",
    "For columns with numerical data type(int64 or float64), we use the median() function from pandas to find the median value in that particular column and insert the identified value into all missing points in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0.00\n",
       "Gender               2.12\n",
       "Married              0.49\n",
       "Dependents           2.44\n",
       "Education            0.00\n",
       "Self_Employed        5.21\n",
       "ApplicantIncome      0.00\n",
       "CoapplicantIncome    0.00\n",
       "LoanAmount           3.58\n",
       "Loan_Amount_Term     2.28\n",
       "Credit_History       8.14\n",
       "Property_Area        0.00\n",
       "Loan_Status          0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*(data.isnull().sum()/len(data.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.519355Z",
     "start_time": "2024-01-17T09:13:10.511866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing data \n",
    "data['Gender'].fillna(data['Gender'].mode()[0], inplace=True)\n",
    "data['Married'].fillna(data['Married'].mode()[0], inplace=True)\n",
    "data['Dependents'].fillna(data['Dependents'].mode()[0], inplace=True)\n",
    "data['Self_Employed'].fillna(data['Self_Employed'].mode()[0], inplace=True)\n",
    "data['Credit_History'].fillna(data['Credit_History'].mode()[0], inplace=True)\n",
    "data['Loan_Amount_Term'].fillna(data['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "data['LoanAmount'].fillna(data['LoanAmount'].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the ID column because it is not used in the process of training a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.521840Z",
     "start_time": "2024-01-17T09:13:10.520164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop ID column\n",
    "data = data.drop('Loan_ID',axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again if all missing values in the dataset has been handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.525150Z",
     "start_time": "2024-01-17T09:13:10.522607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T18:54:34.003611Z",
     "start_time": "2023-03-28T18:54:33.988691Z"
    }
   },
   "source": [
    "Finally, the dataset does not have any missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to evaluate class distribution\n",
    "Identifying the class distribution helps us to know if the dataset is balanced or not. The value_counts() method from the pandas package can evaluate the class distribution by showing the total number of each unique value in the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.528250Z",
     "start_time": "2024-01-17T09:13:10.525966Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    422\n",
       "0    192\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Loan_status column\n",
    "data.Loan_Status.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This shows that in this dataset, the distribution in the target column is unequal. There are more 1 values (Yes) than 0 values (No)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split data into feature and target variables\n",
    "\n",
    "The next step is to split data into feature and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.530875Z",
     "start_time": "2024-01-17T09:13:10.529116Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Split features and target from  data\n",
    "X = data.drop('Loan_Status',axis = 1)\n",
    "y = data.Loan_Status.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The target is the Loan_Status variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess the features\n",
    "\n",
    "However, before we train the machine learning model, we need to transform our features into numerical values so that the machine learning model can understand the data. In this case, we will use: \n",
    "\n",
    "- The **MinMaxScaler()** method from scikit-learn to scale the minimum and maximum values to be 0 and 1, respectively, for the columns with int64 and float64 data types.\n",
    "- The **get_dummies()** method from pandas to convert categorical variables into indicator variables. These variables will have a value of 0 or 1. This method can automatically identify categorical variables and convert them into indicator variables with a value of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.535347Z",
     "start_time": "2024-01-17T09:13:10.531525Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Scale the numerical columns with MinMaxScaler() \n",
    "X[\"ApplicantIncome\"] = MinMaxScaler().fit_transform(X[\"ApplicantIncome\"].values.reshape(-1,1))\n",
    "X[\"LoanAmount\"] = MinMaxScaler().fit_transform(X[\"LoanAmount\"].values.reshape(-1,1))\n",
    "X[\"CoapplicantIncome\"] = MinMaxScaler().fit_transform(X[\"CoapplicantIncome\"].values.reshape(-1,1))\n",
    "X[\"Loan_Amount_Term\"] = MinMaxScaler().fit_transform(X[\"Loan_Amount_Term\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.541383Z",
     "start_time": "2024-01-17T09:13:10.537627Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change categorical features to numerical with get_dummies() \n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "#Convert the DataFrame to a NumPy array. \n",
    "X = X.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train a base machine learning model\n",
    "\n",
    "In this example,we will train the logistic regression algorithm with default hyperparameter values using the cross-validation technique to check the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.543503Z",
     "start_time": "2024-01-17T09:13:10.542144Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifier\n",
    "logistic_classifier = LogisticRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `cross_val_score()` method from scikit-learn to train and evaluate a machine learning model across numerous folds of the dataset. This cross-validation method provides a more comprehensive understanding of the modelâ€™s performance across the entire dataset than a simple train/test split.\n",
    "\n",
    "\n",
    "To use `cross_val_score()` method, we need to define the following parameters:\n",
    "\n",
    "1. `estimator`: The machine learning model object to fit the data\n",
    "2. `X`: The data/features to fit the machine learning model on\n",
    "3. `y`: The target variable of the model classification or regression tasks\n",
    "4. `scoring`: The evaluation error metric to use\n",
    "5. `cv`: The number of splits to use (example 3).\n",
    "\n",
    "\n",
    "The main goal is to prevent model over-fitting and promote model generalization.\n",
    "\n",
    "\n",
    "Note: The machine learning modelâ€™s performance will be evaluated using the f1_score evaluation metric. We use f1_score because we have an unequal number of classes in the Loan_Status variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.982743Z",
     "start_time": "2024-01-17T09:13:10.544110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7305\n"
     ]
    }
   ],
   "source": [
    "# Define function to evaluate f1_score\n",
    "def f1_scorer(estimator, X, y):\n",
    "    y_preds = estimator.predict(X)\n",
    "    f1 = f1_score(y, y_preds, average='macro')\n",
    "    return round(f1, 4)\n",
    "\n",
    "\n",
    "# Implement and run the cross-val-score method\n",
    "score = cross_val_score(estimator=logistic_classifier,\n",
    "                        X=X,\n",
    "                        y=y,\n",
    "                        scoring=f1_scorer,\n",
    "                        cv=3,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Print the mean score\n",
    "print(round(score.mean(), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The mean score of our machine learning model is 0.7305 which is a good performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implement a random search method\n",
    "\n",
    "Because we know how well the machine learning model works with the default hyperparameter values, we can try to improve the modelâ€™s performance by using the random search method to find the combination of hyperparameter values that can give an F1-score of more than 0.7305\n",
    "\n",
    "The logistic regression has multiple hyperparameters, as shown below:\n",
    "\n",
    "LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None) [source](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "However for this example, we will use the following important hyperparameters to find the right combination of their values to get an F1-score greater than 0.7305.\n",
    "\n",
    "- `penalty`: Specifies the penalty's norm\n",
    "- `c`: The inverse of the regularization strength\n",
    "- `Solver`: The algorithm to use in the optimization problem\n",
    "- `tol`: The tolerance for stopping criteria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To implement a random search method using the scikit-learn library, we need to define the following important parameters.\n",
    "\n",
    "- `estimator`: The machine learning algorithm to train with different combinations of\n",
    "hyperparameter values\n",
    "- `param_distributions`: The dictionary with parameter names (string value) as keys and distributions or lists of parameters to try (search space)\n",
    "- `n_iter`: Number of iterations\n",
    "- `scoring`: The method to evaluate the performance of the cross-validated model. For this example, we will use the F1-score.\n",
    "- `CV`: The number of folds for cross-validation. The standard numbers are 5 and 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.989499Z",
     "start_time": "2024-01-17T09:13:10.985597Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameters for random search method\n",
    "\n",
    "#1. Estimator\n",
    "logistic_classifier = LogisticRegression()\n",
    "\n",
    "#2. Param distributions (define the search space)\n",
    "distributions = dict(penalty=['l2', 'l1', 'elasticnet'],\n",
    "                     C=[0.01, 0.1, 1.0,0.001],\n",
    "                     solver=['sag', 'saga','liblinear'],\n",
    "                     tol=[1e-3, 1e-4, 1e-5, 1e-6])\n",
    "\n",
    "#3.Number of iterations\n",
    "n_iter = 30\n",
    "\n",
    "#4. Scoring\n",
    "scoring = f1_scorer\n",
    "\n",
    "#5. Cross-validation splitting strategy\n",
    "cv = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: We need to read the algorithm documentation to understand the function of each hyperparameter and the types of values we can add to the params distribution. For logistic\n",
    "regression, we can read [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "The next step is to import RandomizedSearchCV from scikit-learn library and instantiate the\n",
    "random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:10.993011Z",
     "start_time": "2024-01-17T09:13:10.990635Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the random search method from scikit-learn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define search\n",
    "search = RandomizedSearchCV(estimator=logistic_classifier,\n",
    "                            param_distributions=distributions,\n",
    "                            n_iter=n_iter,\n",
    "                            scoring=scoring,\n",
    "                            cv=cv,\n",
    "                            random_state=1236)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once everything has been defined, the search is executed using the fit() method with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:11.079914Z",
     "start_time": "2024-01-17T09:13:10.993798Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Execute search\n",
    "results = search.fit(X , y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: The time it takes to run the search could range anywhere from a few minutes to hours, depending on the scope of the search space, dataset size, and the processing power of the hardware."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At the end of the search, we can use the following attributes to access all the results.\n",
    "\n",
    "- `best_estimator`: The estimator that gave the highest score\n",
    "- `best_params`: The combination of hyperparameters that gave the best results\n",
    "- `best_scores`: The mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:11.082595Z",
     "start_time": "2024-01-17T09:13:11.080912Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: LogisticRegression(penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "# Show the best estimator\n",
    "print(\"best estimator:\", results.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:11.084845Z",
     "start_time": "2024-01-17T09:13:11.083399Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best combination of hyperparameters: {'tol': 0.0001, 'solver': 'saga', 'penalty': 'l1', 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Show the best combination of hyperparameters\n",
    "print(\"best combination of hyperparameters:\", results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T09:13:11.087096Z",
     "start_time": "2024-01-17T09:13:11.085550Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# Show the best score after performing random search method\n",
    "print(\"Best score:\", round(results.best_score_,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The best score is 0.7319, which is slightly greater than 0.7305.\n",
    "\n",
    "As we can see the performance of the machine learning model has improved compared to the machine learning model trained with default hyperparameters. This shows that despite its simplicity, random search has the ability to identify optimal combinations of hyperparameters that result in good model performance, especially when the search space is not large\n",
    "\n",
    "However, if we try to rerun it, it may be able to provide better results than this. Sometimes, it may produce bad results because it does not try all possible combinations of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages of the random search method\n",
    "\n",
    "Simplicity: The random search method is a simple and straightforward method for hyperparameter optimization, as it does not require any knowledge about\n",
    "the structure of the optimization landscape or the relationships between different hyperparameters.\n",
    "\n",
    "Less computational power: The random search method does not require large amounts of computational power compared to other methods for hyperparameter\n",
    "optimization because we can define the number of combinations of hyperparameters to try.\n",
    "\n",
    "Flexibility: Random search is easily configured to various model and hyperparameter spaces and is compatible with different evaluation metrics to\n",
    "calculate the performance.\n",
    "\n",
    "Potential: Despite its simplicity, random search has the ability to identify good combinations of hyperparameters that result in good model\n",
    "performance, particularly when the search space is not large.\n",
    "\n",
    "# Disadvantages of the random search method\n",
    "\n",
    "Deficient: It is less effective compared to advanced methods such as grid search or Bayesian optimization because it doesnâ€™t guarantee to give the \n",
    "best combination of hyperparameters for optimal model performance. This is because it does not try all possible combinations of hyperparameters.\n",
    "\n",
    "Lack of reproducibility: The results of a random search are difficult to recreate because the search itself is based on random sampling. This makes \n",
    "it impossible to reproduce the results. It is not always easy to determine which group of hyperparameters was utilized for a particular model or to\n",
    "reproduce the results because it always randomly selects the combination of hyperparameters.\n",
    "\n",
    "The datasetâ€™s characteristics, the ML algorithm we are trying to optimize, and various combinations of hyperparameters can all affect the effectiveness\n",
    "of the random search method. Therefore, depending on how it is implemented in our ML project, it can sometimes result in an ML model with better \n",
    "performance or poorer performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0dc12b859b976848fa811fad33b4f2aa47124b6c15239b18f9dcbea69ef542e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
